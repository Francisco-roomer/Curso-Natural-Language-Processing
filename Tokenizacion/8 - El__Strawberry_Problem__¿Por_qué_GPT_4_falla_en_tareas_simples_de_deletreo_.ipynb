{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# El Caso Curioso de \"Strawberry\": ¿Por qué la IA no sabe contar letras?\n",
        "\n",
        "Este es un ejemplo famoso en el mundo de la IA. Si le pides a un modelo que cuente letras, a veces falla estrepitosamente.\n",
        "¿Por qué? Porque el modelo **no ve letras**, ve tokens (números).\n",
        "\n",
        "Vamos a demostrar por qué matemáticamente el modelo no puede encontrar la letra 'r' dentro de la palabra \"strawberry\" si solo mira los tokens."
      ],
      "metadata": {
        "id": "oOao3zmCSs6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aseguramos que tiktoken esté cargado\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "print(\"--- Desglose de la palabra 'Strawberry' ---\")\n",
        "\n",
        "# 1. Tokenizamos la palabra\n",
        "strawberry_tokens = tokenizer.encode('strawberry')\n",
        "\n",
        "# 2. Vemos qué \"pedazos\" (tokens) está viendo realmente la IA\n",
        "for t in strawberry_tokens:\n",
        "    decoded = tokenizer.decode([t])\n",
        "    print(f'Token ID {t:<6} = \"{decoded}\"')\n",
        "\n",
        "print(\"\\n--- Buscando la letra 'r' ---\")\n",
        "\n",
        "# 3. Buscamos el token de la letra 'r' sola\n",
        "r_token = tokenizer.encode('r')\n",
        "print(f'El token para la letra \"r\" solita es: {r_token}')\n",
        "\n",
        "# 4. Preguntamos: ¿Está el número de la \"r\" dentro de la lista de números de \"strawberry\"?\n",
        "is_r_present = r_token[0] in strawberry_tokens\n",
        "\n",
        "print(f\"¿Existe el token {r_token} dentro de {strawberry_tokens}?\")\n",
        "print(f\"Respuesta: {is_r_present}\")\n",
        "\n",
        "print(\"\\nCONCLUSIÓN ERRÓNEA DE LA IA:\")\n",
        "print('Como el token de \"r\" no está en la lista, ¡la IA podría pensar que no hay letras \"r\"!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svHGbTdLStFX",
        "outputId": "b1703063-66f6-4df1-93af-6e31cfa025ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Desglose de la palabra 'Strawberry' ---\n",
            "Token ID 496    = \"str\"\n",
            "Token ID 675    = \"aw\"\n",
            "Token ID 15717  = \"berry\"\n",
            "\n",
            "--- Buscando la letra 'r' ---\n",
            "El token para la letra \"r\" solita es: [81]\n",
            "¿Existe el token [81] dentro de [496, 675, 15717]?\n",
            "Respuesta: False\n",
            "\n",
            "CONCLUSIÓN ERRÓNEA DE LA IA:\n",
            "Como el token de \"r\" no está en la lista, ¡la IA podría pensar que no hay letras \"r\"!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### La Solución: Volver al Texto Humano (Decodificar)\n",
        "\n",
        "Para realizar tareas a nivel de caracteres (como contar letras, hacer acrósticos o rimas complejas), **siempre** debemos convertir los tokens de vuelta a texto (string) antes de procesar.\n",
        "\n",
        "Al decodificar, recuperamos la cadena de caracteres completa y Python ya puede contar correctamente."
      ],
      "metadata": {
        "id": "CPTzrl47S3gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### La Solución: Volver al Texto Humano (Decodificar)\n",
        "\n",
        "Para realizar tareas a nivel de caracteres (como contar letras, hacer acrósticos o rimas complejas), **siempre** debemos convertir los tokens de vuelta a texto (string) antes de procesar.\n",
        "\n",
        "Al decodificar, recuperamos la cadena de caracteres completa y Python ya puede contar correctamente."
      ],
      "metadata": {
        "id": "yjQl8oRETAoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Decodificar la lista de tokens para volver a tener texto plano\n",
        "strawberry_string = tokenizer.decode(strawberry_tokens)\n",
        "print(f'Texto recuperado: \"{strawberry_string}\"')\n",
        "\n",
        "# 2. Decodificar el token de 'r' (o simplemente usar el string 'r')\n",
        "r_string = tokenizer.decode(r_token)\n",
        "print(f'Letra a buscar: \"{r_string}\"')\n",
        "\n",
        "# 3. Contar usando métodos de string de Python (la forma correcta)\n",
        "count = strawberry_string.count(r_string)\n",
        "\n",
        "print(f'\\nCORRECCIÓN:')\n",
        "print(f'La palabra \"{strawberry_string}\" tiene {count} letras \"{r_string}\".')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DijMrxBZS30u",
        "outputId": "1b7edb48-84f4-478d-fdf4-d804f2db2d9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto recuperado: \"strawberry\"\n",
            "Letra a buscar: \"r\"\n",
            "\n",
            "CORRECCIÓN:\n",
            "La palabra \"strawberry\" tiene 3 letras \"r\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CupkVpfTEVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# El \"Strawberry Problem\": ¿Por qué GPT-4 falla en tareas simples de deletreo?"
      ],
      "metadata": {
        "id": "HJZppw0XTFRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ceguera de Tokens: Limitaciones de BPE en el Procesamiento de Caracteres"
      ],
      "metadata": {
        "id": "dKENq3OJTHsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión del Ejercicio\n",
        "\n",
        "Este ejercicio demuestra una limitación fundamental de la arquitectura de los LLMs modernos:\n",
        "\n",
        "1.  **Ceguera a los Caracteres:** El modelo **no ve** la palabra \"Strawberry\" como una secuencia de letras (S-t-r-a...). La ve como una secuencia de números (Tokens).\n",
        "2.  **El Token es una Caja Cerrada:** Para el modelo, el token `strawberry` es una unidad indivisible (un número entero). No puede \"mirar dentro\" de ese número para contar cuántas \"r\" tiene, a menos que se le fuerce a descomponerlo (decodificarlo).\n",
        "3.  **Matemática vs. Lenguaje:** La operación `r in strawberry` falla porque matemáticamente el número que representa a la 'r' (ej: 345) no está dentro de la lista de números que forman 'strawberry' (ej: [456, 122]).\n",
        "\n",
        "**Resumen:** Para realizar operaciones a nivel de letra (conteo, inversión de palabras, acrósticos), **siempre** es necesario `decodificar` los tokens a texto plano primero."
      ],
      "metadata": {
        "id": "1AK94TviT0r1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7RIBa7DT00N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}