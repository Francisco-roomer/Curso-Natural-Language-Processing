{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKAZ6Oh9UQQX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio Creativo: Tu Nombre de Rapero Generado por IA"
      ],
      "metadata": {
        "id": "i3HuCx4_UsFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generador de Nombres de Rapero\n",
        "En este ejercicio vamos a jugar con los números de los tokens.\n",
        "La idea es tomar tu información personal, convertirla en tokens, ordenarlos y aplicar una fórmula matemática \"mística\" para descubrir cuál es tu nombre artístico según GPT-4.\n",
        "\n",
        "1.  **Entrada:** Definimos tus datos.\n",
        "2.  **Procesamiento:** Convertimos todo a tokens y los ordenamos.\n",
        "3.  **Algoritmo:**\n",
        "    * Parte 1: Basada en la primera letra de tu nombre.\n",
        "    * Parte 2: Basada en la última letra de tu apellido.\n",
        "    * Parte 3: Una mezcla matemática de tus tokens (el mayor dividido por el menor más el promedio de los del medio)."
      ],
      "metadata": {
        "id": "-qr0ZIIUUtnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "# Aseguramos que tiktoken esté instalado e importado\n",
        "try:\n",
        "    import tiktoken\n",
        "except ImportError:\n",
        "    !pip install tiktoken\n",
        "    import tiktoken\n",
        "\n",
        "# Inicializamos el tokenizador\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "# --- 1. DATOS DE ENTRADA ---\n",
        "# Puedes cambiar esto por tus datos reales\n",
        "first_name = \"Michael\"\n",
        "last_name = \"Jordan\"\n",
        "fav_color = \"Red\"\n",
        "\n",
        "# Unimos todo en un solo texto\n",
        "text = ' '.join([first_name, last_name, fav_color])\n",
        "print(f\"Texto base: '{text}'\")\n",
        "\n",
        "# --- 2. TOKENIZACIÓN Y ORDENAMIENTO ---\n",
        "# Codificamos el texto a números (tokens)\n",
        "idx = tokenizer.encode(text)\n",
        "\n",
        "# Ordenamos la lista de tokens de menor a mayor\n",
        "idx.sort()\n",
        "print(f\"Tokens ordenados: {idx}\")\n",
        "\n",
        "# --- 3. FUNCIÓN DE LIMPIEZA ---\n",
        "# Esta función nos ayuda a evitar tokens \"raros\" (símbolos, espacios vacíos, bytes extraños)\n",
        "# Devuelve True si el token NO es texto normal (alfanumérico)\n",
        "def not_normal(token_str):\n",
        "    pattern = re.compile(r'^[A-Za-z0-9]+$') # Solo letras y números\n",
        "    return not bool(pattern.fullmatch(token_str.strip()))\n",
        "\n",
        "# --- 4. CÁLCULO DEL NOMBRE DE RAPERO ---\n",
        "\n",
        "# PARTE 1: Primera letra del nombre - 1\n",
        "# Tomamos el token de la primera letra\n",
        "first_letter_token = tokenizer.encode(first_name[0])[0]\n",
        "part1 = first_letter_token - 1\n",
        "\n",
        "# Si el resultado es un símbolo raro, seguimos restando hasta hallar una letra/número normal\n",
        "while not_normal(tokenizer.decode([part1])):\n",
        "    part1 -= 1 # Vamos hacia atrás en el vocabulario\n",
        "\n",
        "# PARTE 2: Última letra del apellido + 1\n",
        "last_letter_token = tokenizer.encode(last_name[-1])[0]\n",
        "part2 = last_letter_token + 1\n",
        "\n",
        "# Opcional: Limpiamos también la parte 2 si sale rara (sumando)\n",
        "while not_normal(tokenizer.decode([part2])):\n",
        "    part2 += 1\n",
        "\n",
        "# PARTE 3: (Último token / Primero) + Promedio del medio\n",
        "# Usamos los tokens ordenados en 'idx'\n",
        "# idx[-1] es el más grande, idx[0] el más pequeño\n",
        "# idx[1:-1] son todos los del medio\n",
        "val_part3 = (idx[-1] / idx[0]) + np.mean(idx[1:-1])\n",
        "part3 = int(val_part3) # Convertimos a entero para que sea un token válido\n",
        "\n",
        "# --- 5. RESULTADO FINAL ---\n",
        "rapper_tokens = [part1, part2, part3]\n",
        "rapper_name = tokenizer.decode(rapper_tokens)\n",
        "\n",
        "print(\"-\" * 20)\n",
        "print(f'Tokens generados: {rapper_tokens}')\n",
        "print(f'My rapper name is \"{rapper_name}\"')\n",
        "print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hviKBxrxUsNt",
        "outputId": "1e2bc8d6-d1da-4c3d-a58f-717375521380"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto base: 'Michael Jordan Red'\n",
            "Tokens ordenados: [3816, 17527, 26597]\n",
            "--------------------\n",
            "Tokens generados: [43, 78, 17533]\n",
            "My rapper name is \"Lo Dub\"\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOqHtv6fUwMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicación del Código\n",
        "\n",
        "* **`idx.sort()`:** Al ordenar los tokens, desordenamos el significado original de las palabras, quedándonos solo con sus valores numéricos para hacer \"numerología\".\n",
        "* **`not_normal()`:** El vocabulario de GPT-4 tiene muchos tokens extraños (símbolos chinos, bytes raw, emojis). Este bucle `while` asegura que tu nombre sea legible forzando al algoritmo a buscar el siguiente token \"normal\" vecino.\n",
        "* **El Resultado:** Es probable que obtengas una combinación de sílabas o palabras cortas que suenan extraño. ¡Ese es tu nombre generado por la \"creatividad\" matemática del tokenizador!"
      ],
      "metadata": {
        "id": "PbJmTS3mU3IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUYr_Ds5U3W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2TfNodWVLmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicación del Algoritmo: \"Nombre de Rapero\"\n",
        "\n",
        "Este ejercicio es un juego matemático para demostrar que, para la IA, las palabras no son más que una bolsa de números. Al manipular esos números con sumas, restas y promedios, podemos generar \"nuevas palabras\".\n",
        "\n",
        "Aquí está el desglose de lo que hace el código paso a paso:\n",
        "\n",
        "#### 1. Desordenar el Significado (`idx.sort`)\n",
        "Primero, tomamos tus datos (Nombre + Apellido + Color) y los convertimos en una lista de tokens.\n",
        "* **Lo normal:** Los tokens mantienen un orden para que la frase tenga sentido (Sujeto + Verbo + Predicado).\n",
        "* **Lo que hacemos aquí:** Al ejecutar `idx.sort()`, destruimos el orden gramatical. Ahora solo tenemos una lista de números ordenados de menor a mayor. Tratamos al lenguaje como pura estadística.\n",
        "\n",
        "#### 2. El Filtro de Limpieza (`not_normal`)\n",
        "El vocabulario de GPT-4 (`cl100k_base`) contiene ~100,000 tokens. Muchos de ellos no son palabras, sino símbolos raros, espacios vacíos, emojis o fragmentos de código.\n",
        "* Esta función verifica si un token es \"normal\" (letras y números) usando una expresión regular (`re`).\n",
        "* Si el cálculo matemático nos da un símbolo extraño (ej: `¾` o `\\n`), el bucle `while` nos obliga a seguir buscando hasta encontrar un token legible.\n",
        "\n",
        "#### 3. La \"Fórmula Mágica\"\n",
        "El nombre se construye uniendo 3 piezas generadas matemáticamente:\n",
        "\n",
        "* **Parte 1 (El Prefijo):**\n",
        "    * Toma la **primera letra** de tu nombre.\n",
        "    * Busca su ID numérico y le **resta 1**.\n",
        "    * Es decir, busca el \"vecino anterior\" en el diccionario de la IA.\n",
        "\n",
        "* **Parte 2 (El Sufijo):**\n",
        "    * Toma la **última letra** de tu apellido.\n",
        "    * Busca su ID numérico y le **suma 1**.\n",
        "    * Es decir, busca el \"vecino siguiente\".\n",
        "\n",
        "* **Parte 3 (El Núcleo):**\n",
        "    * Aquí usamos la lista ordenada `idx`.\n",
        "    * Aplica una fórmula arbitraria: `(Token_Mayor / Token_Menor) + Promedio(Tokens_Del_Medio)`.\n",
        "    * El resultado es un número nuevo que representa una mezcla matemática de todos tus datos personales.\n",
        "\n",
        "#### Resultado Final\n",
        "El código une los tres resultados `[part1, part2, part3]` y los decodifica. El resultado suele ser una palabra inventada o un sonido extraño (ej: *\"Lz-qwe-Bop\"*), que actúa como tu nombre artístico único generado por la \"creatividad matemática\" del tokenizador."
      ],
      "metadata": {
        "id": "tTivSiIQVU1d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zC2tAofcVU_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}