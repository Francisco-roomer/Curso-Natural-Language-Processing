{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. El texto\n",
        "# Creamos una lista con frases famosas (nuestro \"corpus\" o cuerpo de texto)\n",
        "texto = [ 'Pienso luego existo',\n",
        "          'Solo se que no se nada',\n",
        "          'Ser o no ser esa es la cuestion' ]\n",
        "\n",
        "texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsAX949UVJG3",
        "outputId": "ee18cd74-a278-4036-8542-47816bf73740"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pienso luego existo',\n",
              " 'Solo se que no se nada',\n",
              " 'Ser o no ser esa es la cuestion']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación**: Aquí simplemente estamos declarando una variable texto que es una lista. Dentro de la lista, tenemos 3 elementos, y cada elemento es un \"string\" (cadena de texto)."
      ],
      "metadata": {
        "id": "-A1bIZMbdpt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 2** Separar en palabras (Tokenización simple)\n",
        "Las computadoras no leen frases, leen unidades. Vamos a usar la librería re (Expresiones Regulares) para cortar la frase donde haya espacios."
      ],
      "metadata": {
        "id": "iXQ_2-Qnd2q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Separar en palabras dividiendo por espacios\n",
        "import re\n",
        "\n",
        "# Probamos solo con la primera frase (índice 0)\n",
        "re.split('\\s', texto[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGaxpACVd_DB",
        "outputId": "271a2346-0346-4ff5-f203-a8d293d921a2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-173545576.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re.split('\\s', texto[0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pienso', 'luego', 'existo']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación**:\n",
        "\n",
        "*   import re: Traemos la herramienta de búsqueda de texto.\n",
        "\n",
        "*   \\s: Significa \"espacio en blanco\".\n",
        "\n",
        "*   texto[0]: Toma \"Pienso luego existo\".\n",
        "\n",
        "*   Resultado: Una lista rota: ['Pienso', 'luego', 'existo'].\n"
      ],
      "metadata": {
        "id": "0UbETDmheLtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 3**: Recombinar (Unir de nuevo)\n",
        "A veces necesitas limpiar una lista de palabras y volver a pegarla para que sea un texto normal."
      ],
      "metadata": {
        "id": "Z0vWYoTQeurO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Recombinar en un solo texto (Join)\n",
        "# Usamos un espacio ' ' como pegamento para unir la lista anterior\n",
        "' '.join( re.split('\\s', texto[0]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "m-tVy3mHeyRw",
        "outputId": "c6d6c748-d44b-4329-c971-a554e5fd87c6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-3246002443.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  ' '.join( re.split('\\s', texto[0]) )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pienso luego existo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:**\n",
        "\n",
        "' '.join(...): Toma los pedazos que separamos arriba y los une usando un espacio entre ellos. Es el proceso inverso al paso anterior."
      ],
      "metadata": {
        "id": "ICVCr_X6e8qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 4:** Normalización (Minúsculas y Unificación)\n",
        "Para que la computadora entienda que \"Ser\" y \"ser\" son lo mismo, convertimos todo a minúsculas y juntamos todas las frases en una sola bolsa de palabras."
      ],
      "metadata": {
        "id": "uSPIiSBqfDLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Convertir a minúsculas y juntar todo\n",
        "# Unimos todas las frases del texto original, las pasamos a minúsculas y cortamos por espacios\n",
        "todas_las_palabras = re.split('\\s', ' '.join(texto).lower())\n",
        "\n",
        "todas_las_palabras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-bHR-5QfGb4",
        "outputId": "37050e34-5771-422f-8f18-fb679488e6c5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-3736589652.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  todas_las_palabras = re.split('\\s', ' '.join(texto).lower())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pienso',\n",
              " 'luego',\n",
              " 'existo',\n",
              " 'solo',\n",
              " 'se',\n",
              " 'que',\n",
              " 'no',\n",
              " 'se',\n",
              " 'nada',\n",
              " 'ser',\n",
              " 'o',\n",
              " 'no',\n",
              " 'ser',\n",
              " 'esa',\n",
              " 'es',\n",
              " 'la',\n",
              " 'cuestion']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:**\n",
        "\n",
        "' '.join(texto): Pega las 3 frases originales en una sola línea gigante.\n",
        "\n",
        ".lower(): Lo convierte todo a minúsculas (\"Pienso\" -> \"pienso\").\n",
        "\n",
        "Resultado: Una lista gigante con todas las palabras de todas las frases, una detrás de otra."
      ],
      "metadata": {
        "id": "PPuGeNCFfRdS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FruewtHnfaKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 5: Crear el Vocabulario (Lexicón)**\n",
        "Aquí ocurre la magia. De todas las palabras repetidas, queremos saber cuáles son las palabras únicas que existen en nuestro universo de datos."
      ],
      "metadata": {
        "id": "7nLc_bnlfawi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Encontrar las palabras únicas (Vocabulario)\n",
        "# 'set' elimina duplicados, 'sorted' las ordena alfabéticamente\n",
        "vocabulario = sorted(set(todas_las_palabras))\n",
        "\n",
        "vocabulario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o7kUrZyfimg",
        "outputId": "677f909b-0b57-4aa2-ef73-70f6ff17a80f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cuestion',\n",
              " 'es',\n",
              " 'esa',\n",
              " 'existo',\n",
              " 'la',\n",
              " 'luego',\n",
              " 'nada',\n",
              " 'no',\n",
              " 'o',\n",
              " 'pienso',\n",
              " 'que',\n",
              " 'se',\n",
              " 'ser',\n",
              " 'solo']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Hay {len(todas_las_palabras)} palabras en el texto total, pero solo {len(vocabulario)} palabras únicas en el vocabulario')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkgLNPixfmC3",
        "outputId": "51803c97-59bb-4a06-963c-eef45c39567f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 17 palabras en el texto total, pero solo 14 palabras únicas en el vocabulario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:**\n",
        "\n",
        "set(...): Es un conjunto matemático. Elimina automáticamente cualquier palabra repetida (ej: si \"ser\" aparece 2 veces, solo deja 1).\n",
        "\n",
        "sorted(...): Ordena la lista de la A a la Z.\n",
        "\n",
        "Importancia: Este vocabulario es la \"base de datos\" de palabras que tu sistema conoce."
      ],
      "metadata": {
        "id": "3ou86tLffsTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 6:** Crear el Codificador (Encoder) y Decodificador (Decoder)\n",
        "Las redes neuronales y los algoritmos no entienden letras (\"h-o-l-a\"), solo entienden números. Necesitamos un mapa para traducir."
      ],
      "metadata": {
        "id": "vAT3PwQOf0Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. El codificador es un diccionario de Python\n",
        "palabra_a_indice = {}\n",
        "\n",
        "for i, palabra in enumerate(vocabulario):\n",
        "  palabra_a_indice[palabra] = i\n",
        "\n",
        "palabra_a_indice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA8mgr0Yf27v",
        "outputId": "9d83b800-8f93-4eb3-907f-98497132f5c2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuestion': 0,\n",
              " 'es': 1,\n",
              " 'esa': 2,\n",
              " 'existo': 3,\n",
              " 'la': 4,\n",
              " 'luego': 5,\n",
              " 'nada': 6,\n",
              " 'no': 7,\n",
              " 'o': 8,\n",
              " 'pienso': 9,\n",
              " 'que': 10,\n",
              " 'se': 11,\n",
              " 'ser': 12,\n",
              " 'solo': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Y un decodificador (el proceso inverso)\n",
        "indice_a_palabra = {}\n",
        "\n",
        "for i, palabra in enumerate(vocabulario):\n",
        "  indice_a_palabra[i] = palabra\n",
        "\n",
        "indice_a_palabra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IHA-LPQf6Bw",
        "outputId": "d56bc16d-97a6-4473-8eb1-bccb29b24698"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'cuestion',\n",
              " 1: 'es',\n",
              " 2: 'esa',\n",
              " 3: 'existo',\n",
              " 4: 'la',\n",
              " 5: 'luego',\n",
              " 6: 'nada',\n",
              " 7: 'no',\n",
              " 8: 'o',\n",
              " 9: 'pienso',\n",
              " 10: 'que',\n",
              " 11: 'se',\n",
              " 12: 'ser',\n",
              " 13: 'solo'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:**\n",
        "\n",
        "Codificador (palabra_a_indice): Si le das la palabra \"luego\", te da el número 4 (por ejemplo).\n",
        "\n",
        "Decodificador (indice_a_palabra): Si le das el número 4, te devuelve la palabra \"luego\".\n"
      ],
      "metadata": {
        "id": "ebOyD6XHgDkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 7:** Pruebas del Mapa\n",
        "Verificamos que el mapa funciona."
      ],
      "metadata": {
        "id": "RT7Ql8MdgcXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos el mapa\n",
        "print(f'La palabra \"ser\" tiene el índice {palabra_a_indice[\"ser\"]}')\n",
        "print(f'El índice 2 corresponde a la palabra \"{indice_a_palabra[2]}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePhIoonhge3x",
        "outputId": "b28f9d23-23bf-4540-b647-c75622b10a02"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La palabra \"ser\" tiene el índice 12\n",
            "El índice 2 corresponde a la palabra \"esa\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 8:** Generador de Frases Aleatorias (Solo por diversión)\n",
        "Ya que tenemos los números, podemos pedirle a la máquina que elija números al azar y los traduzca a palabras para \"inventar\" una frase."
      ],
      "metadata": {
        "id": "e4xOZBj-gohi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Hacer citas falsas\n",
        "import numpy as np\n",
        "\n",
        "# Seleccionar 5 índices (números) al azar basados en el tamaño de nuestro vocabulario\n",
        "indices_random = np.random.randint(0, len(vocabulario), size=5)\n",
        "\n",
        "# Traducir esos números a palabras\n",
        "frase_loca = [ indice_a_palabra[i] for i in indices_random ]\n",
        "\n",
        "# Unir y mostrar\n",
        "print('Frase generada: ', ' '.join(frase_loca))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSDFKa5Qgqkf",
        "outputId": "423b3797-6eac-4ac1-8dad-cde62effd0f7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase generada:  cuestion cuestion ser no la\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:** Esto simula cómo una IA \"escribe\", aunque aquí es totalmente al azar, por lo que la frase probablemente no tenga sentido (ej: \"luego nada ser cuestion existo\")."
      ],
      "metadata": {
        "id": "4ck5TVN2g6UB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKoRjHXSg77P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 9: Vistazo a la Tokenización Real**\n",
        "Así es como ve la computadora el texto original. Ya no ve \"Pienso luego existo\", ve [5, 4, 1]."
      ],
      "metadata": {
        "id": "4faZqU-ihAxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Traducir todo el texto original a números\n",
        "texto_como_enteros = [ palabra_a_indice[palabra] for palabra in todas_las_palabras ]\n",
        "\n",
        "texto_como_enteros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4fKQO5-hDAQ",
        "outputId": "4453ee42-46f9-46f1-9bb3-8003ef5eff30"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 5, 3, 13, 11, 10, 7, 11, 6, 12, 8, 7, 12, 2, 1, 4, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Y convertir los números de vuelta a texto para verificar\n",
        "for token_i in texto_como_enteros:\n",
        "  print(f'Token {token_i:2}: {indice_a_palabra[token_i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJlarW4chGjo",
        "outputId": "7def0209-d6d6-4580-ebad-0bbac8ecd696"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token  9: pienso\n",
            "Token  5: luego\n",
            "Token  3: existo\n",
            "Token 13: solo\n",
            "Token 11: se\n",
            "Token 10: que\n",
            "Token  7: no\n",
            "Token 11: se\n",
            "Token  6: nada\n",
            "Token 12: ser\n",
            "Token  8: o\n",
            "Token  7: no\n",
            "Token 12: ser\n",
            "Token  2: esa\n",
            "Token  1: es\n",
            "Token  4: la\n",
            "Token  0: cuestion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen Final: Acabas de transformar lenguaje humano (no estructurado) en una secuencia numérica (datos estructurados) que una máquina puede procesar."
      ],
      "metadata": {
        "id": "4NJylxxghNF6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFWaqagThO14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}