{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este código es un ejemplo perfecto de un flujo de trabajo completo de NLP (Procesamiento de Lenguaje Natural) \"en la vida real\". A diferencia de los ejemplos anteriores donde inventábamos frases, aquí descargamos un libro real de internet, lo limpiamos (que es la parte más difícil y sucia) y creamos nuestro motor de traducción a números.\n",
        "\n",
        "Aquí tienes la explicación estructurada para tu material de apoyo."
      ],
      "metadata": {
        "id": "KPcPX-5HscZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taller Avanzado: Procesamiento de Datos Reales (Web Scraping & Cleaning)**"
      ],
      "metadata": {
        "id": "nlPPWzK9sias"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo:** Aprender a descargar texto crudo de internet, limpiar la \"basura\" informática (símbolos raros, errores de codificación) y prepararlo para una Inteligencia Artificial.##\n",
        "\n",
        "Paso 1: Obtención de Datos (La Fuente)\n",
        "En lugar de escribir frases manuales, usamos la librería requests para ir a la web del Proyecto Gutenberg y descargar el libro \"La Máquina del Tiempo\" (The Time Machine)."
      ],
      "metadata": {
        "id": "f5ECHhFQspLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import re\n",
        "import string\n",
        "\n",
        "# 1. Descargar texto crudo de internet\n",
        "# Hacemos una petición (GET) a la URL del archivo de texto\n",
        "libro = requests.get('https://www.gutenberg.org/files/35/35-0.txt')\n",
        "\n",
        "# Extraemos solo el contenido de texto\n",
        "texto = libro.text\n",
        "\n",
        "print(f\"Tipo de dato: {type(texto)}\")\n",
        "print(f\"Longitud del texto: {len(texto)} caracteres\")\n",
        "\n",
        "# Vemos un pedazo del texto sucio\n",
        "print(texto[:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3AC0sF0suDc",
        "outputId": "c131bf95-002e-4ba2-8324-2dd215fa2c8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dato: <class 'str'>\n",
            "Longitud del texto: 182973 caracteres\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK 35 ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The Time Machine\r\n",
            "\r\n",
            "An Invention\r\n",
            "\r\n",
            "by H. G. Wells\r\n",
            "\r\n",
            "\r\n",
            "CONTENTS\r\n",
            "\r\n",
            " I Introduction\r\n",
            " II The Machine\r\n",
            " III The Time Traveller Returns\r\n",
            " IV Time Travelling\r\n",
            " V In the Golden Age\r\n",
            " VI The Sunset of Mankind\r\n",
            " VII A Sudden Shock\r\n",
            " VIII Explanation\r\n",
            " IX The Morlocks\r\n",
            " X When Night Came\r\n",
            " XI The Palace of Green Porcelain\r\n",
            " XII In the Darkness\r\n",
            " XIII The Trap of the White Sphinx\r\n",
            " XIV The Further Vision\r\n",
            " XV The Time Traveller’s Return\r\n",
            " XVI After the Story\r\n",
            " Epilogue\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " I.\r\n",
            " Introduction\r\n",
            "\r\n",
            "\r\n",
            "The Time Traveller (for so it will be convenient to speak of him) was\r\n",
            "expounding a recondite matter to us. His pale grey eyes shone and\r\n",
            "twinkled, and his usually pale face was flushed and animated. The fire\r\n",
            "burnt brightly, and the soft radiance of the incandescent lights in the\r\n",
            "lilies of silver caught the bubbles that flashed and passed in our\r\n",
            "glasses. Our chairs, being his patents, embraced and caressed us rather\r\n",
            "than submitted to be sat upon, and there was that luxurious\r\n",
            "after-dinner atmosphere, when thought runs gracefully free of the\r\n",
            "trammels of precision. And he put it to us in this way—marking the\r\n",
            "points with a lean forefinger—as we sat and lazily admired his\r\n",
            "earnestness over this new paradox (as we thought it) and his fecundity.\r\n",
            "\r\n",
            "“You must follow me carefully. I shall have to controvert one or two\r\n",
            "ideas that are almost universally accepted. The geometry, for instance,\r\n",
            "they taught you at school is founded on a misconception.”\r\n",
            "\r\n",
            "“Is not that rather a large thing to expect us to begin upon?” said\r\n",
            "Filby, an argumentative person with red hair.\r\n",
            "\r\n",
            "“I do not mean to ask you to accept anything without reasonable ground\r\n",
            "for it. You will soon admit as much as I need from you. You know of\r\n",
            "course that a mathematical line, a line of thickness _nil_, has no real\r\n",
            "existence. They taught you that? Neither has a mathematical plane.\r\n",
            "These things are mere abstractions.”\r\n",
            "\r\n",
            "“That is all right,” said the Psychologis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Al imprimir esto, verás mucha \"basura\" como cabeceras, licencias y quizás caracteres extraños."
      ],
      "metadata": {
        "id": "fVPjPXz6s8F0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Limpieza Profunda (Data Cleaning)\n",
        "El texto de internet suele venir con errores de codificación (esos símbolos raros como â\\x80\\x9c). Esto pasa cuando se mezclan formatos de texto (UTF-8 vs Windows-1252). Si no limpias esto, tu IA aprenderá basura."
      ],
      "metadata": {
        "id": "Q6GqxjCstCa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Definir la basura a eliminar\n",
        "# Estos son códigos de caracteres rotos comunes en textos antiguos de la web\n",
        "cadenas_a_reemplazar = [\n",
        "                 '\\r\\n\\r\\nâ\\x80\\x9c', # Nuevo párrafo raro\n",
        "                 'â\\x80\\x9c',         # Comilla de apertura rota\n",
        "                 'â\\x80\\x9d',         # Comilla de cierre rota\n",
        "                 '\\r\\n',              # Salto de línea de Windows\n",
        "                 'â\\x80\\x94',         # Guion largo roto\n",
        "                 'â\\x80\\x99',         # Apóstrofe roto\n",
        "                 'â\\x80\\x98',         # Comilla simple rota\n",
        "                 '_',                 # Subguiones usados para énfasis\n",
        "                 ]\n",
        "\n",
        "# 3. Reemplazar esa basura por espacios\n",
        "for cadena in cadenas_a_reemplazar:\n",
        "  # Compilamos la expresión regular para buscar esa cadena exacta\n",
        "  regexp = re.compile(r'%s' % cadena)\n",
        "  # Sustituimos por un espacio\n",
        "  texto = regexp.sub(' ', texto)\n",
        "\n",
        "# 4. Limpieza final agresiva\n",
        "# Eliminar cualquier cosa que NO sea código ASCII estándar (quita tildes y ñ si las hubiera)\n",
        "texto = re.sub(r'[^\\x00-\\x7F]+', ' ', texto)\n",
        "\n",
        "# Eliminar números (para que '1999' no sea una palabra)\n",
        "texto = re.sub(r'\\d+', '', texto)\n",
        "\n",
        "# Convertir todo a minúsculas\n",
        "texto = texto.lower()\n",
        "\n",
        "# Veamos cómo quedó ahora más limpio\n",
        "print(texto[:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy0wjltLtEpk",
        "outputId": "c2c52fef-57ff-417d-ed47-b656575a9bcf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** start of the project gutenberg ebook  ***     the time machine  an invention  by h. g. wells   contents   i introduction  ii the machine  iii the time traveller returns  iv time travelling  v in the golden age  vi the sunset of mankind  vii a sudden shock  viii explanation  ix the morlocks  x when night came  xi the palace of green porcelain  xii in the darkness  xiii the trap of the white sphinx  xiv the further vision  xv the time traveller s return  xvi after the story  epilogue      i.  introduction   the time traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. his pale grey eyes shone and twinkled, and his usually pale face was flushed and animated. the fire burnt brightly, and the soft radiance of the incandescent lights in the lilies of silver caught the bubbles that flashed and passed in our glasses. our chairs, being his patents, embraced and caressed us rather than submitted to be sat upon, and there was that luxurious after-dinner atmosphere, when thought runs gracefully free of the trammels of precision. and he put it to us in this way marking the points with a lean forefinger as we sat and lazily admired his earnestness over this new paradox (as we thought it) and his fecundity.   you must follow me carefully. i shall have to controvert one or two ideas that are almost universally accepted. the geometry, for instance, they taught you at school is founded on a misconception.    is not that rather a large thing to expect us to begin upon?  said filby, an argumentative person with red hair.   i do not mean to ask you to accept anything without reasonable ground for it. you will soon admit as much as i need from you. you know of course that a mathematical line, a line of thickness  nil , has no real existence. they taught you that? neither has a mathematical plane. these things are mere abstractions.    that is all right,  said the psychologist.   nor, having only length, breadth, and thickness, can a cube h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concepto Clave:** Aquí es donde limpiarías los Emojis si no los quisieras, o los \"Jajajajaja\" infinitos."
      ],
      "metadata": {
        "id": "mX-imPujtZ3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 3:** Parsing (Tokenización Inteligente)\n",
        "Ahora cortamos el texto en palabras. Usamos la puntuación (puntos, comas, exclamaciones) como tijeras."
      ],
      "metadata": {
        "id": "NDxhlO5ntiGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Separar por puntuación\n",
        "print(f\"Signos de puntuación que usaremos para cortar: {string.punctuation}\")\n",
        "\n",
        "# Creamos una regla que diga: \"Corta donde haya puntuación O espacios\"\n",
        "puntos_regex = fr'[{string.punctuation}\\s]+'\n",
        "\n",
        "palabras = re.split(puntos_regex, texto)\n",
        "\n",
        "# 6. Filtrado final\n",
        "# Quitamos espacios vacíos que hayan quedado\n",
        "palabras = [item.strip() for item in palabras if item.strip()]\n",
        "\n",
        "# Quitamos palabras de una sola letra (como 'a', 'y', 'o' en español, o 'I', 'a' en inglés)\n",
        "# Esto reduce el ruido, aunque a veces se pierde información útil.\n",
        "palabras = [item for item in palabras if len(item) > 1]\n",
        "\n",
        "print(f\"\\nPrimeras 50 palabras procesadas:\\n{palabras[:50]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnVCvK1Ptj3M",
        "outputId": "76060371-d173-4d87-99c7-c5a6d8af86ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Signos de puntuación que usaremos para cortar: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\n",
            "Primeras 50 palabras procesadas:\n",
            "['start', 'of', 'the', 'project', 'gutenberg', 'ebook', 'the', 'time', 'machine', 'an', 'invention', 'by', 'wells', 'contents', 'introduction', 'ii', 'the', 'machine', 'iii', 'the', 'time', 'traveller', 'returns', 'iv', 'time', 'travelling', 'in', 'the', 'golden', 'age', 'vi', 'the', 'sunset', 'of', 'mankind', 'vii', 'sudden', 'shock', 'viii', 'explanation', 'ix', 'the', 'morlocks', 'when', 'night', 'came', 'xi', 'the', 'palace', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhubJrAotvXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 4:** Estadísticas del Vocabulario\n",
        "Aquí medimos la riqueza del texto."
      ],
      "metadata": {
        "id": "sxsrKHdtt1LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el vocabulario (palabras únicas ordenadas)\n",
        "vocabulario = sorted(set(palabras))\n",
        "\n",
        "nPalabras = len(palabras)      # Total de palabras en el libro\n",
        "nLexico = len(vocabulario)     # Total de palabras ÚNICAS que sabe el sistema\n",
        "\n",
        "print(f'Total de palabras en el texto: {nPalabras}')\n",
        "print(f'Tamaño del vocabulario (Tokens únicos): {nLexico}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AerxXujgt3_9",
        "outputId": "fbf8d336-c736-4a3c-f3e6-be01dbbcaee5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de palabras en el texto: 30698\n",
            "Tamaño del vocabulario (Tokens únicos): 4589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 5:** Creación del Motor (Encoder/Decoder)\n",
        "Creamos los diccionarios y las funciones para traducir. Nota que aquí el encoder usa un bucle for, que es más fácil de leer que una list comprehension, y usa numpy para ser más eficiente con grandes datos."
      ],
      "metadata": {
        "id": "FNLi7QTYt_2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionarios de mapeo\n",
        "word2idx = {w:i for i,w in enumerate(vocabulario)}\n",
        "idx2word = {i:w for i,w in enumerate(vocabulario)}\n",
        "\n",
        "# Imprimir una muestra del diccionario (cada 87 palabras para ver variedad)\n",
        "print(\"Muestra del diccionario:\")\n",
        "for i in list(word2idx.items())[0:10000:87]:\n",
        "  print(i)\n",
        "\n",
        "# --- FUNCIÓN ENCODER (Palabras -> Vector Numérico) ---\n",
        "def encoder(lista_palabras, diccionario_cod):\n",
        "  # Pre-creamos un vector de ceros del tamaño exacto (más rápido en memoria)\n",
        "  idxs = np.zeros(len(lista_palabras), dtype=int)\n",
        "\n",
        "  # Llenamos el vector\n",
        "  for i, palabra in enumerate(lista_palabras):\n",
        "    # OJO: Aquí asumimos que la palabra EXISTE en el diccionario.\n",
        "    # En un sistema real, necesitarías un manejo de errores para palabras desconocidas.\n",
        "    idxs[i] = diccionario_cod[palabra]\n",
        "\n",
        "  return idxs\n",
        "\n",
        "# --- FUNCIÓN DECODER (Vector Numérico -> Texto) ---\n",
        "def decoder(indices, diccionario_dec):\n",
        "  return ' '.join([diccionario_dec[i] for i in indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Y0VJMKuCs0",
        "outputId": "1b696170-d0fb-428c-ff7c-906139a5c257"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestra del diccionario:\n",
            "('abandon', 0)\n",
            "('aimlessly', 87)\n",
            "('apologise', 174)\n",
            "('attained', 261)\n",
            "('behaved', 348)\n",
            "('both', 435)\n",
            "('can', 522)\n",
            "('cheerfully', 609)\n",
            "('coat', 696)\n",
            "('contents', 783)\n",
            "('culminating', 870)\n",
            "('delay', 957)\n",
            "('dimness', 1044)\n",
            "('dragging', 1131)\n",
            "('edition', 1218)\n",
            "('everywhere', 1305)\n",
            "('facilities', 1392)\n",
            "('find', 1479)\n",
            "('footfall', 1566)\n",
            "('furnishing', 1653)\n",
            "('gold', 1740)\n",
            "('hallo', 1827)\n",
            "('high', 1914)\n",
            "('ideas', 2001)\n",
            "('inextinguishable', 2088)\n",
            "('invest', 2175)\n",
            "('lamp', 2262)\n",
            "('likewise', 2349)\n",
            "('manhood', 2436)\n",
            "('minerals', 2523)\n",
            "('mysteries', 2610)\n",
            "('novelty', 2697)\n",
            "('outbreaks', 2784)\n",
            "('paws', 2871)\n",
            "('plato', 2958)\n",
            "('previously', 3045)\n",
            "('questionings', 3132)\n",
            "('reflecting', 3219)\n",
            "('return', 3306)\n",
            "('sandals', 3393)\n",
            "('senses', 3480)\n",
            "('shrinking', 3567)\n",
            "('slit', 3654)\n",
            "('special', 3741)\n",
            "('stick', 3828)\n",
            "('sudden', 3915)\n",
            "('tap', 4002)\n",
            "('thrice', 4089)\n",
            "('treat', 4176)\n",
            "('unfrozen', 4263)\n",
            "('vertical', 4350)\n",
            "('wearisome', 4437)\n",
            "('wonderful', 4524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_H9LVuJguHEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 6: Validación y Pruebas**\n",
        "Probamos que nuestro sistema no rompa el texto. Tomamos un pedazo aleatorio del libro, lo convertimos a números y lo traemos de vuelta."
      ],
      "metadata": {
        "id": "bnUP4cYTuPJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prueba manual simple\n",
        "print(\"\\n--- Prueba Simple ---\")\n",
        "codificado = encoder(['the', 'time', 'machine'], word2idx)\n",
        "print(f\"Codificado: {codificado}\")\n",
        "print(f\"Decodificado: {decoder([1, 3, 10], idx2word)}\") # Nota: [1,3,10] son indices inventados para probar\n",
        "\n",
        "\n",
        "# 2. Prueba de \"Ida y Vuelta\" (Round-trip)\n",
        "print(\"\\n--- Prueba de Ida y Vuelta Aleatoria ---\")\n",
        "\n",
        "# Elegimos un punto de partida al azar en el libro\n",
        "inicio_idx = np.random.choice(nPalabras)\n",
        "\n",
        "# Tomamos 10 palabras seguidas desde ese punto\n",
        "indices_secuenciales = np.arange(inicio_idx, inicio_idx + 10)\n",
        "secuencia_palabras = [ palabras[i] for i in indices_secuenciales ]\n",
        "\n",
        "print('Texto Original:')\n",
        "print(secuencia_palabras)\n",
        "\n",
        "print('\\nTokens (Versión numérica):')\n",
        "secuencia_tokens = encoder(secuencia_palabras, word2idx)\n",
        "print(secuencia_tokens)\n",
        "\n",
        "print('\\nTexto Decodificado (Reconstrucción):')\n",
        "print(decoder(secuencia_tokens, idx2word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSsAnwquR2M",
        "outputId": "f293fa4b-ab60-43fb-a74c-0461b59af2da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Prueba Simple ---\n",
            "Codificado: [4042 4109 2416]\n",
            "Decodificado: abandoned abnormally absent\n",
            "\n",
            "--- Prueba de Ida y Vuelta Aleatoria ---\n",
            "Texto Original:\n",
            "['again', 'put', 'one', 'more', 'drop', 'of', 'oil', 'on', 'the', 'quartz']\n",
            "\n",
            "Tokens (Versión numérica):\n",
            "[  74 3116 2742 2569 1158 2731 2736 2740 4042 3129]\n",
            "\n",
            "Texto Decodificado (Reconstrucción):\n",
            "again put one more drop of oil on the quartz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPqPrsltuVmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}